{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN2jnvSE4ZXrEGuJEfKYHg5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"B13JrjHosCnw"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model"]},{"cell_type":"code","source":["# Ensure you have the necessary YOLO weights and config files.\n","# Download YOLO weights: https://pjreddie.com/media/files/yolov3.weights\n","# Download YOLO config: https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg\n","# Download COCO names: https://github.com/pjreddie/darknet/blob/master/data/coco.names\n","\n","# Path to YOLO config and weights files\n","yolo_cfg = 'yolov3.cfg'\n","yolo_weights = 'yolov3.weights'\n","yolo_names = 'coco.names'\n"],"metadata":{"id":"ZIP0AIjnsOke"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load YOLO model\n","net = cv2.dnn.readNet(yolo_weights, yolo_cfg)\n","\n","# Load COCO names\n","with open(yolo_names, 'r') as f:\n","    classes = f.read().strip().split('\\n')"],"metadata":{"id":"0b0PFTB7sRvV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to process an image and run YOLO detection\n","def detect_objects(image_path):\n","    image = cv2.imread(image_path)\n","    height, width = image.shape[:2]\n","    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n","    net.setInput(blob)\n","    outs = net.forward(get_output_layers(net))\n","\n","    class_ids = []\n","    confidences = []\n","    boxes = []\n","\n","    for out in outs:\n","        for detection in out:\n","            scores = detection[5:]\n","            class_id = np.argmax(scores)\n","            confidence = scores[class_id]\n","            if confidence > 0.5:  # Confidence threshold\n","                center_x = int(detection[0] * width)\n","                center_y = int(detection[1] * height)\n","                w = int(detection[2] * width)\n","                h = int(detection[3] * height)\n","                x = int(center_x - w / 2)\n","                y = int(center_y - h / 2)\n","                class_ids.append(class_id)\n","                confidences.append(float(confidence))\n","                boxes.append([x, y, w, h])\n","\n","    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n","\n","    for i in indices:\n","        i = i[0]\n","        box = boxes[i]\n","        x, y, w, h = box[0], box[1], box[2], box[3]\n","        draw_prediction(image, class_ids[i], confidences[i], x, y, x + w, y + h)\n","\n","    return image"],"metadata":{"id":"ygJtsbQjsVMs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Helper functions\n","def get_output_layers(net):\n","    layer_names = net.getLayerNames()\n","    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n","    return output_layers\n","\n","def draw_prediction(image, class_id, confidence, x, y, x_plus_w, y_plus_h):\n","    label = str(classes[class_id])\n","    if label == 'car':  # Only draw bounding box for cars\n","        color = (0, 255, 0)  # Green color for bounding box\n","        cv2.rectangle(image, (x, y), (x_plus_w, y_plus_h), color, 2)\n","        cv2.putText(image, f'{label} {confidence:.2f}', (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n"],"metadata":{"id":"QmjpZe5asaGA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Process training images (example)\n","train_dir = 'training_images'\n","for img_file in os.listdir(train_dir):\n","    img_path = os.path.join(train_dir, img_file)\n","    detected_image = detect_objects(img_path)\n","    cv2.imshow('Detected Image', detected_image)\n","    cv2.waitKey(0)\n","\n","cv2.destroyAllWindows()"],"metadata":{"id":"CdCeU1RhsdnN"},"execution_count":null,"outputs":[]}]}